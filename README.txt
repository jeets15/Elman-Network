Can a Recurrent Neural Network learn an allocentric policy from multiple egocentric experiences
of an agent?

We start by developing a Q learning algorithm which is capable of computing the q values of a grid world
with an agent.

single gridworld from various egocentric perspectives of the agent are used to form a dataset containing the
State, Action, and q-value pair for each state.

This dataset is supplied to the Elman network in order to compute if the network is capable enough to find the
underlying pattern within the dataset and predict the next state/ action.
which it has not been trained on.

The basic idea is to determine how does a simple RN  compare against various traditional techniques such as
q-learning.






intro 2000
convince reader of topic, presenting research question.

create diagram of hidden unit when

similarity of hidden unit activation diagram.